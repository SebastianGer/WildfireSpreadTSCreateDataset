{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "evaluate",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "pycharm-cbd103e4",
   "language": "python",
   "display_name": "PyCharm (CalFireMonitoring)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tx6_DvC7VLDq",
    "outputId": "3b888926-6fe2-4361-b423-2b655664b110",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread, imsave\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "!pip install array2gif\n",
    "from array2gif import write_gif\n",
    "import datetime"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already satisfied: array2gif in /Users/zhaoyu/PycharmProjects/SampleDemo/venv/lib/python3.7/site-packages (1.0.4)\r\nRequirement already satisfied: numpy in /Users/zhaoyu/PycharmProjects/SampleDemo/venv/lib/python3.7/site-packages (from array2gif) (1.18.5)\r\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xce3LEOGWgEk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k51c9TjbVbxa",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    " \n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    " \n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    " \n",
    " \n",
    "lstm_model = tf.keras.models.load_model('lstm_model5', custom_objects={'f1_m':f1_m})"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Chn3NY49M9iL",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "PATH = '/Users/zhaoyu/PycharmProjects/CalFireMonitoring/data/evaluate/V31179/reference_dataset/V31179 dataset_ref_trial5300*250.npy'\n",
    "# predict_dataset = np.load('/Users/zhaoyu/PycharmProjects/SampleDemo/notebooks/bond_fire dataset_ref_trial5256*240.npy')\n",
    "predict_dataset = np.load(PATH)\n",
    "# predict_dataset = np.load('/Users/zhaoyu/PycharmProjects/SampleDemo/notebooks/Doctor_creek_fire dataset_ref_trial5304*208.npy')\n",
    "# predict_dataset = np.load('/content/drive/My Drive/evaluate/blue_ridge_fire dataset_ref_trial5.npy')\n",
    "# predict_dataset = np.load('/content/drive/My Drive/evaluate/silverado_fire dataset_ref_trial5.npy')\n",
    "# predict_dataset = np.load('/content/drive/My Drive/evaluate/August_complex dataset_ref_trial5.npy')\n",
    "# predict_dataset = np.load('/content/drive/My Drive/evaluate/CZU_lighting_complex dataset_ref_trial5.npy')\n",
    "# predict_dataset = np.load('/content/drive/My Drive/evaluate/LNU_lighting_complex dataset_ref_trial5.npy')\n",
    "# predict_dataset = np.load('/content/drive/My Drive/evaluate/SCU_lighting_complex dataset_ref_trial5.npy')\n",
    "# predict_dataset = np.load('/content/drive/MyDrive/evaluate/chuckegg_creek_fire dataset_ref_trial5300*250.npy')\n",
    "# predict_dataset = np.load('/content/drive/MyDrive/evaluate/babine_complex dataset_ref_trial5300*250.npy')\n",
    "# predict_dataset = np.load('/content/drive/MyDrive/evaluate/fraser_complex dataset_ref_trial5300*250.npy')\n",
    "# predict_dataset = np.load('/content/drive/MyDrive/evaluate/stikine_complex dataset_ref_trial5300*250.npy')\n",
    "\n",
    "predict_dataset = predict_dataset.transpose((1,0,2))"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVQeaY2by2R5",
    "outputId": "873c1dd3-0511-4f49-a23f-4ab691b704a9",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import cv2\n",
    "predict_dataset = predict_dataset[:,:,:121]\n",
    "\n",
    "new_predict_dataset = np.zeros((predict_dataset.shape[0],predict_dataset.shape[1],predict_dataset.shape[2]))\n",
    "for i in range(predict_dataset.shape[1]):\n",
    "  # print(predict_dataset_image[:,i,:].mean())\n",
    "  ret,predict_dataset[:,i,:] = cv2.threshold(predict_dataset[:,i,:],max(predict_dataset[:,i,:].mean(), 3),100,cv2.THRESH_TOZERO)\n",
    "\n",
    "predict_dataset_mean = predict_dataset.mean()\n",
    "predict_dataset_std = predict_dataset.std()\n",
    "# predict_dataset_label = predict_dataset[:, 20:40, 25:]\n",
    "# predict_dataset_label_mean = predict_dataset_label.mean()\n",
    "# predict_dataset_label_std = predict_dataset_label.std()\n",
    "\n",
    "new_predict_dataset = (predict_dataset - predict_dataset_mean) / predict_dataset_std\n",
    "\n",
    "# predict_dataset_label_norm = (predict_dataset_label - predict_dataset_label_mean) / predict_dataset_label_std\n",
    "oupput_lstm = lstm_model.predict(new_predict_dataset)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vXZ_0LB4mDFx",
    "outputId": "52c08e67-1c7e-4b2a-e60e-4f21bf8115e5",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "source": [
    "# import cv2\n",
    "import numpy.ma as npm\n",
    "x_size = int(PATH[-11:-8])-10\n",
    "y_size = int(PATH[-7:-4])-10\n",
    "lstm_gif_list = []\n",
    "origin_gif_list = []\n",
    "label_gif_list = []\n",
    "concat_gif = []\n",
    "output_acc = []\n",
    "output = np.zeros((x_size, y_size, oupput_lstm.shape[1]))\n",
    "for j in range(43,48):\n",
    "    index_day = j\n",
    "\n",
    "    lstm_conf = oupput_lstm[:, index_day, 0].reshape((x_size, y_size))\n",
    "    origin_pic = predict_dataset[:, index_day, 12].reshape((x_size, y_size))\n",
    "    ret,lstm_conf = cv2.threshold(lstm_conf,0,100,cv2.THRESH_TOZERO)\n",
    "    ret,lstm_conf = cv2.threshold(lstm_conf,lstm_conf.mean(),100,cv2.THRESH_TOZERO)\n",
    "    # print(np.median(lstm_conf))\n",
    "    mask = origin_pic==0\n",
    "    # print(mask)\n",
    "    output[:,:,j] = lstm_conf\n",
    "    o_min = lstm_conf.min()\n",
    "    o_max = lstm_conf.max()\n",
    "    print(\"{:02d}:00\".format(j)+\"to\"+\"{:02d}:59\".format(j))\n",
    "    image = npm.array(lstm_conf, mask=mask)\n",
    "    # plt.imshow(lstm_conf)\n",
    "    # plt.show()\n",
    "    plt.imshow(origin_pic)\n",
    "    plt.show()\n",
    "    output_acc.append(lstm_conf)\n",
    " \n",
    "    lstm_conf_png = np.zeros((lstm_conf.shape[0],lstm_conf.shape[1],4))\n",
    "    lstm_conf_png[:,:,0] = ((lstm_conf - o_min) * (1/(o_max - o_min) * 255)).astype('uint8')\n",
    "    lstm_conf_png[:,:,3] = ((lstm_conf - o_min) * (1/(o_max - o_min) * 255)).astype('uint8')\n",
    "    plt.imshow(lstm_conf_png)\n",
    "    plt.show()\n",
    "    origin_pic = ((origin_pic - predict_dataset.min()) * (1/(predict_dataset.max() - predict_dataset.min()) * 255)).astype('uint8')\n",
    "    # imsave('../img/lstm_conf' + str(j) + '.png', lstm_conf_png.astype(np.uint8))\n",
    "eval_img = np.stack(output_acc, axis=2).sum(axis=2)\n",
    "\n",
    "# np.save('output_Doctor_creek_fire_acc246*230.npy', eval_img)\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ]
}